{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Op9nv5GtO0DY"
   },
   "source": [
    "# Animal Vision - Model Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIEIG2E_TvD0"
   },
   "source": [
    "# 1. Create Dataset and Dataloaders - data_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1670003329514,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "sOmAwTYRYMHp",
    "outputId": "954276ac-2268-4fda-91c5-a19e39d33f43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating \n",
    "PyTorch datasets and dataloaders for\n",
    "Image classification data\n",
    "\"\"\"\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(train_dir: str,\n",
    "                       test_dir: str,\n",
    "                       transform: transforms.Compose,\n",
    "                       batch_size: int,\n",
    "                       num_workers: int = NUM_WORKERS):\n",
    "    \"\"\"\n",
    "    Create training and testing dataloaders.\n",
    "\n",
    "    Args:\n",
    "      train_dir: Train directory path,\n",
    "      test_dir: Test directory path,\n",
    "      transform: torchvision transforms compose class to transform the data,\n",
    "      batch_size: Total sample per batch,\n",
    "      num_workers: An integer for the number of workers durning dataloaders\n",
    "\n",
    "    Return:\n",
    "      Returns a tuple of (train_dataloaders, test_dataloaders, class_names).\n",
    "    \"\"\"\n",
    "    # Create datasets using ImageFolder\n",
    "    train_data = datasets.ImageFolder(root=train_dir, \n",
    "                                      transform=transform)\n",
    "    test_data = datasets.ImageFolder(root=test_dir, \n",
    "                                     transform=transform)\n",
    "    \n",
    "    # Get class name\n",
    "    class_names = train_data.classes\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataloaders = DataLoader(dataset=train_data,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=num_workers,\n",
    "                                   pin_memory=True)\n",
    "    test_dataloaders = DataLoader(dataset=test_data,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=num_workers,\n",
    "                                  pin_memory=True)\n",
    "\n",
    "    return train_dataloaders, test_dataloaders, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2931,
     "status": "ok",
     "timestamp": 1670003332380,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "if_nbGJGFBKx",
    "outputId": "9f4f85b7-0d7a-400f-c2e1-c8357760e5e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fd895789b80>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fd90811fa00>,\n",
       " ['LION', 'TIGER', 'WOLF'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_setup\n",
    "import os\n",
    "from torchvision import transforms\n",
    "train_dir = 'data/lion_tiger_wolf/train'\n",
    "test_dir = 'data/lion_tiger_wolf/val'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "train_dataloaders, test_dataloaders, class_names =  data_setup.create_dataloaders(train_dir,\n",
    "                                                                                  test_dir,\n",
    "                                                                                  transform,\n",
    "                                                                                  BATCH_SIZE,\n",
    "                                                                                  NUM_WORKERS)\n",
    "train_dataloaders, test_dataloaders, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQUX7xlmhfe5"
   },
   "source": [
    "# 2. Creating a Model script - model_builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1670003332382,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "9KAzNoACjmRA",
    "outputId": "ac97fd15-378c-496a-ff79-fa16edcea5c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_builder.py\n",
    "\"\"\"\n",
    "Contains PyTorch Model code to \n",
    "initiate a custom model to train and test a dataset \n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates a neural network architecture similar to the TinyVGG architecture from\n",
    "    here: https://github.com/poloclub/cnn-explainer/tree/master/tiny-vgg and for visuals \n",
    "    here: https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "    Args:\n",
    "      input_shape: An integer for the input units. E.g. 3 for RBG and 1 for grayscale.\n",
    "      output_shape: An integer for the output units. E.g. Any number that represents your total labels.\n",
    "      hidden_units: An integer for the hidden units. E.g. Any number to change the filters in the layer.\n",
    "\n",
    "    Return:\n",
    "      A tensor of logits with the length provided as per the output_shape.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, output_shape: int, hidden_units: int):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(input_shape, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_units*13*13,\n",
    "                      output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.classifier(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1670003332384,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "E6Asw4fDHQ9B",
    "outputId": "f44b62b3-03fd-463a-f236-85688a041038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [4, 20, 62, 62]             560\n",
      "              ReLU-2            [4, 20, 62, 62]               0\n",
      "            Conv2d-3            [4, 20, 60, 60]           3,620\n",
      "              ReLU-4            [4, 20, 60, 60]               0\n",
      "         MaxPool2d-5            [4, 20, 30, 30]               0\n",
      "            Conv2d-6            [4, 20, 28, 28]           3,620\n",
      "              ReLU-7            [4, 20, 28, 28]               0\n",
      "            Conv2d-8            [4, 20, 26, 26]           3,620\n",
      "              ReLU-9            [4, 20, 26, 26]               0\n",
      "        MaxPool2d-10            [4, 20, 13, 13]               0\n",
      "          Flatten-11                  [4, 3380]               0\n",
      "           Linear-12                     [4, 3]          10,143\n",
      "================================================================\n",
      "Total params: 21,563\n",
      "Trainable params: 21,563\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 11.62\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 11.89\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, TinyVGG(\n",
       "   (conv_block1): Sequential(\n",
       "     (0): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (1): ReLU()\n",
       "     (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (3): ReLU()\n",
       "     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (conv_block2): Sequential(\n",
       "     (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (1): ReLU()\n",
       "     (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (3): ReLU()\n",
       "     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (classifier): Sequential(\n",
       "     (0): Flatten(start_dim=1, end_dim=-1)\n",
       "     (1): Linear(in_features=3380, out_features=3, bias=True)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_builder\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "baseline_model = model_builder.TinyVGG(input_shape=3,\n",
    "                                       output_shape=len(class_names),\n",
    "                                       hidden_units=20).to(device)\n",
    "summary(baseline_model,(3, 64, 64), 4, device=device), baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCKPWVnUIXxJ"
   },
   "source": [
    "# 3. Create the training and testing script - engine.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1670003346154,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "6fItbpQVvoJ2",
    "outputId": "d07438dd-f002-4de6-cea3-7496d7efb03d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile engine.py\n",
    "\"\"\"\n",
    "Contains training and testing function in PyTorch\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Function for training the model\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"\n",
    "  Trains a PyTorch model.\n",
    "  Turns the model to a training mode and applies steps\n",
    "  like loss, accuracy metrics, optimizer.\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A Dataloader instance that needs to be trained on.\n",
    "    loss_fn: A PyTorch Loss function for calculating the loss durning the training.\n",
    "    optimizer: A Pytorch Optimizer to help reduce the loss function.\n",
    "    device: A target device either 'cuda' or 'cpu'.\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics. \n",
    "  \"\"\"\n",
    "  # model in train mode\n",
    "  model.train()\n",
    "  # setup train_loss and train_acc\n",
    "  train_loss, train_acc = 0, 0\n",
    "  # Loop through dataloader\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    # define the target device to data\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    # forward pass\n",
    "    y_pred = model(X)\n",
    "    # loss and accuracy\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss.item()\n",
    "    # backward propagation    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # calculate accuracy metrics\n",
    "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "  # Calculate the loss and accuracy for the model\n",
    "  train_loss /= len(dataloader)\n",
    "  train_acc /= len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "# function for testing the model\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"\n",
    "  Test a PyTorch model.\n",
    "  Turns the model to a evaluation mode and applies steps\n",
    "  like loss and accuracy metrics.\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A Dataloader instance that needs to be trained on.\n",
    "    loss_fn: A PyTorch Loss function for calculating the loss durning the training.\n",
    "    device: A target device either 'cuda' or 'cpu'.\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.  \n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  # setup train_loss and train_acc\n",
    "  test_loss, test_acc = 0, 0\n",
    "  # Turn on inference context manager\n",
    "  with torch.inference_mode():\n",
    "    # Loop through dataloader\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "      # define the target device to data\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      # forward pass\n",
    "      test_pred_logits = model(X)\n",
    "      # calculate loss\n",
    "      loss = loss_fn(test_pred_logits, y)\n",
    "      test_loss += loss.item()\n",
    "      # calculate accuracy\n",
    "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "      # Calculate the loss and accuracy for the model\n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "# Function for tracking different experiment\n",
    "def create_writer(experiment_name: str,\n",
    "                  model_name: str,\n",
    "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
    "  \"\"\"\n",
    "  Creates a log directory using tensorboard, in a format runs/timestamp/experiment_name/model_name/extra.\n",
    "  Args: \n",
    "    experiment_name: Name of experiment,\n",
    "    model_name: Name of the model,\n",
    "    extra: Anything extra to add to the directory. Default to None.\n",
    "  Returns:\n",
    "    torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir\n",
    "  \"\"\"\n",
    "  timestamp = datetime.now().strftime(\"%d-%m-%Y\") # time in format DD-MM-YYYY\n",
    "  if extra:\n",
    "    log_dir = os.path.join('runs', timestamp, experiment_name, model_name, extra)\n",
    "  else:\n",
    "    log_dir = os.path.join('runs', timestamp, experiment_name, model_name)\n",
    "  print(f'\\n[INFO] Creating SummaryWriter, saving to: {log_dir}...')\n",
    "  return SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# function for training and testing the model for n epochs.\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          writer: torch.utils.tensorboard.writer.SummaryWriter) -> Dict[str, List]:\n",
    "  \"\"\"\n",
    "  Train and test a PyTorch Model\n",
    "\n",
    "  Passing a model through train_step and test_step for certain\n",
    "  number of epochs and training the model for that epoch loop.\n",
    "  Calculate, print and stores all the metrics durning the training loop.\n",
    "\n",
    "  Args:\n",
    "    model: A pytorch model to be trained.\n",
    "    train_dataloader: A dataloader only for train_step.\n",
    "    test_dataloader: A dataloader only for test_step.\n",
    "    loss_fn: A PyTorch Loss function for calculating the loss durning the training and testing.\n",
    "    optimizer: A Pytorch Optimizer to help reduce the loss function while training the model.\n",
    "    epochs: An integer indicating how much epochs to train the model for.\n",
    "    device: A target device either 'cuda' or 'cpu'.\n",
    "    writer: A SummaryWriter to save all the experiments.  \n",
    "\n",
    "  Returns:\n",
    "    A Dict containing all the values returned by train_step and test_step.\n",
    "    results = {'train_loss': [],\n",
    "               'train_acc': [],\n",
    "               'test_loss': [],\n",
    "               'test_acc': []}\n",
    "  \"\"\"\n",
    "  # Creating a result dict.\n",
    "  results = {'train_loss': [],\n",
    "             'train_acc': [],\n",
    "             'test_loss': [],\n",
    "             'test_acc': []}\n",
    "\n",
    "  # Training and evaluation loop\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(model=model,\n",
    "                                       dataloader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       device=device)\n",
    "    test_loss, test_acc = test_step(model=model,\n",
    "                                    dataloader=test_dataloader,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    device=device)\n",
    "    print(f'Epoch: {epoch+1} | train_loss: {train_loss:.4f} , train_acc: {train_acc:.4f} | test_loss: {test_loss:.4f}, test_acc: {test_acc:.4f}')\n",
    "\n",
    "    # store every epoch results in the results Dict\n",
    "    results['train_loss'].append(train_loss)\n",
    "    results['train_acc'].append(train_acc)\n",
    "    results['test_loss'].append(test_loss)\n",
    "    results['test_acc'].append(test_acc)\n",
    "\n",
    "    # Use the writer to track experiment\n",
    "    if writer:\n",
    "      writer.add_scalars(main_tag='loss',\n",
    "                         tag_scalar_dict={'train_loss': train_loss,\n",
    "                                          'test_loss': test_loss},\n",
    "                         global_step=epoch)\n",
    "      writer.add_scalars(main_tag='Accuracy',\n",
    "                         tag_scalar_dict={'train_acc': train_acc,\n",
    "                                          'test_acc': test_acc},\n",
    "                         global_step=epoch)\n",
    "      # close the writer\n",
    "      writer.close()\n",
    "    else:\n",
    "      pass\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396,
     "referenced_widgets": [
      "d2db99b9c4944e0fa63a14d96e9e43d1",
      "04a58a2e34d8448398af74722b3e77be",
      "1c3354c57d904135adc17fe773b74c11",
      "f69dc78e13a449139d27a49281e95d0a",
      "7fd3c05e65ed47f29179975dd2ff8d9f",
      "395804aae56b4c11a9c62a1f3b58494d",
      "c95a05d5d0df4bbd817488c90ae93a8d",
      "7d91ba25acf04fab905663ac3cf7d22e",
      "10172dbca6a74238973eea0895a4f90a",
      "f6e1a5e2c5a5441e9586bae64ef7353d",
      "9b8bea360dfc4d0fad18169f97d13455"
     ]
    },
    "executionInfo": {
     "elapsed": 161819,
     "status": "ok",
     "timestamp": 1670003515258,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "RBjAVfTUy_ek",
    "outputId": "6300a6f2-2d03-4b15-d532-e2a9bfcd7e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumExpr defaulting to 2 threads.\n",
      "\n",
      "[INFO] Creating SummaryWriter, saving to: runs/02-12-2022/trial/model0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2db99b9c4944e0fa63a14d96e9e43d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0014 , train_acc: 0.4913 | test_loss: 1.0222, test_acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.9242 , train_acc: 0.5823 | test_loss: 0.8787, test_acc: 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.8843 , train_acc: 0.6034 | test_loss: 0.9210, test_acc: 0.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.8459 , train_acc: 0.6373 | test_loss: 0.8804, test_acc: 0.6189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.8081 , train_acc: 0.6595 | test_loss: 0.7865, test_acc: 0.6578\n",
      "\n",
      "Total Training Time: 157.612 seconds\n"
     ]
    }
   ],
   "source": [
    "import engine\n",
    "from torch import nn \n",
    "from timeit import default_timer as timer\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# creating loss, accuracy and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=baseline_model.parameters(), lr=0.001)\n",
    "writer = engine.create_writer('trial', 'model0')\n",
    "\n",
    "# Train model_0\n",
    "model0_start_time = timer()\n",
    "model_0_results = engine.train(baseline_model,\n",
    "                               train_dataloaders,\n",
    "                               test_dataloaders,\n",
    "                               loss_fn,\n",
    "                               optimizer,\n",
    "                               NUM_EPOCHS,\n",
    "                               device,\n",
    "                               writer)\n",
    "model_0_end_time = timer()\n",
    "print(f'\\nTotal Training Time: {model_0_end_time - model0_start_time:.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfwDYE3w17mr"
   },
   "source": [
    "# 4. Save the model script - utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1670003567215,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "dT9vVFP3Pn7S",
    "outputId": "3dde9929-c151-4780-bdf2-e2f8ba9bc79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "\"\"\"\n",
    "Contains various utilities function for PyTorch model training and saving.\n",
    "\"\"\"\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "  \"\"\"\n",
    "  Saves a PyTorch Model to a directory.\n",
    "  Args:\n",
    "    model: A PyTorch model of nn.Module type.\n",
    "    target_dir: A string of directory path.\n",
    "    model_name: A filename for the saved model.\n",
    "                Should include .pth or .pt as a file extention.\n",
    "  \"\"\"\n",
    "  # Create target directory\n",
    "  target_dir_path = Path(target_dir)\n",
    "  target_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  # Create model save path\n",
    "  assert model_name.endswith('.pth') or model_name.endswith('.pt'), 'model_name should end with .pth or .pt'\n",
    "  model_save_path = target_dir_path / model_name\n",
    "\n",
    "  # save the model state_dict\n",
    "  print(f'\\n[INFO] Saving Model to: {model_save_path}')\n",
    "  torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1670003569907,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "JO5R3l2CXnJL",
    "outputId": "c969c232-8eb4-4baa-882f-a9356d6bf514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Saving Model to: models/baseline_model.pth\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "utils.save_model(baseline_model,\n",
    "                 'models',\n",
    "                 'baseline_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIsvRQ4WfX2y"
   },
   "source": [
    "# 5. Train, evaluate and save the model - train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1670003697283,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "w6XbbllGflZU",
    "outputId": "681d67b6-b13d-4151-bd8a-a827b91242d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\"\"\"\n",
    "Trains, evaluate and saves a PyTorch image classification model. \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "import data_setup, engine, model_builder, utils\n",
    "from torchvision import transforms\n",
    "from datetime import datetime\n",
    "\n",
    "# create a parser\n",
    "parser = argparse.ArgumentParser(description='Get some hyperparameters')\n",
    "\n",
    "# get experiment name\n",
    "parser.add_argument('--exp_name',\n",
    "                    default='experiment',\n",
    "                    type=str,\n",
    "                    help='Name of the experiment')\n",
    "# get model name\n",
    "parser.add_argument('--model_name',\n",
    "                    default='model',\n",
    "                    type=str,\n",
    "                    help='Name of the model')\n",
    "# get an arg for num_epochs\n",
    "parser.add_argument(\"--num_epochs\",\n",
    "                    default=10,\n",
    "                    type=int,\n",
    "                    help='The number of epochs to train for')\n",
    "# get an arg for batch_size\n",
    "parser.add_argument(\"--batch_size\",\n",
    "                    default=32,\n",
    "                    type=int,\n",
    "                    help='The number of sample for batch_size')\n",
    "# get an arg for hidden_units\n",
    "parser.add_argument(\"--hidden_units\",\n",
    "                    default=10,\n",
    "                    type=int,\n",
    "                    help='The number of units for hidden layers')\n",
    "# get an arg for learning_rate\n",
    "parser.add_argument(\"--learning_rate\",\n",
    "                    default=0.001,\n",
    "                    type=float,\n",
    "                    help='learning rate for optimizer')\n",
    "# get an arg for training directory\n",
    "parser.add_argument(\"--train_dir\",\n",
    "                    default='data/lion_tiger_wolf/train',\n",
    "                    type=str,\n",
    "                    help='The path for training data')\n",
    "# get an arg for testing directory\n",
    "parser.add_argument(\"--test_dir\",\n",
    "                    default='data/lion_tiger_wolf/val',\n",
    "                    type=str,\n",
    "                    help='The path for test data')\n",
    "# get our arg from the parser\n",
    "args=parser.parse_args()\n",
    "\n",
    "# setup hyperparameters\n",
    "NUM_EPOCHS = args.num_epochs\n",
    "BATCH_SIZE=args.batch_size\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "HIDDEN_UNITS=args.hidden_units\n",
    "LEARNING_RATE= args.learning_rate\n",
    "print(f'\\n[INFO] Training a model for {NUM_EPOCHS} epochs with batch size {BATCH_SIZE} using {HIDDEN_UNITS} hidden units with a learning rate of {LEARNING_RATE}')\n",
    "\n",
    "# setup directories\n",
    "train_dir = args.train_dir\n",
    "test_dir = args.test_dir\n",
    "print(f'[INFO] Training data directory: {train_dir}')\n",
    "print(f'[INFO] Testing data directory: {test_dir}')\n",
    "\n",
    "# setup target device\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Create transform\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create dataloaders using data_setup script\n",
    "train_dataloaders, test_dataloaders, class_names =  data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                                  test_dir=test_dir,\n",
    "                                                                                  transform=data_transform,\n",
    "                                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                                  num_workers=NUM_WORKERS)\n",
    "\n",
    "# Create model using model_builder script\n",
    "model = model_builder.TinyVGG(input_shape=3,\n",
    "                              output_shape=len(class_names),\n",
    "                              hidden_units=HIDDEN_UNITS).to(device)\n",
    "\n",
    "# set loss, accuracy and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# define the summary writer and track our result through tensorboard\n",
    "writer = engine.create_writer(args.exp_name,\n",
    "                              args.model_name)\n",
    "\n",
    "# start training using engine script\n",
    "print(f'\\n[INFO] Starting Model Training...')\n",
    "engine.train(model=model,\n",
    "             train_dataloader=train_dataloaders,\n",
    "             test_dataloader=test_dataloaders,\n",
    "             loss_fn=loss_fn,\n",
    "             optimizer=optimizer,\n",
    "             epochs=NUM_EPOCHS,\n",
    "             device=device,\n",
    "             writer=writer)\n",
    "\n",
    "# save the model using utils script\n",
    "utils.save_model(model=model,\n",
    "                 target_dir='models',\n",
    "                 model_name=args.model_name + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294913,
     "status": "ok",
     "timestamp": 1670003994292,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "kY2ceI1VnaYn",
    "outputId": "41d3b842-2b86-4939-d9dd-5ad6284e9d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Training a model for 5 epochs with batch size 10 using 128 hidden units with a learning rate of 0.0003\n",
      "[INFO] Training data directory: data/lion_tiger_wolf/train\n",
      "[INFO] Testing data directory: data/lion_tiger_wolf/val\n",
      "\n",
      "[INFO] Creating SummaryWriter, saving to: runs/02-12-2022/experiment/model...\n",
      "\n",
      "[INFO] Starting Model Training...\n",
      "  0% 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "Epoch: 1 | train_loss: 0.9884 , train_acc: 0.5105 | test_loss: 0.9205, test_acc: 0.5505\n",
      " 20% 1/5 [04:48<19:14, 288.52s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 104, in <module>\n",
      "    engine.train(model=model,\n",
      "  File \"/content/engine.py\", line 156, in train\n",
      "    train_loss, train_acc = train_step(model=model,\n",
      "  File \"/content/engine.py\", line 45, in train_step\n",
      "    loss.backward()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 396, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py --num_epochs 5 --batch_size 10 --hidden_units 128 --learning_rate 0.0003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVgRBgn0aA1r"
   },
   "source": [
    "# 6. Creating a predict script - predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1670004004693,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "aAaFs37ZaKjF",
    "outputId": "c3649030-105c-4dab-a4b7-f1d57abf3c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict.py\n",
    "\"\"\"\n",
    "Contains code to predict a single image class using a saved model.\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import argparse\n",
    "import model_builder\n",
    "\n",
    "# creating a parser\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# get an image_path\n",
    "parser.add_argument('--image_path',\n",
    "                    help='target image filepath to predict on')\n",
    "# get a saved model\n",
    "parser.add_argument(\"--model_path\",\n",
    "                    default='models/model.pth',\n",
    "                    type=str,\n",
    "                    help='target model to use for prediction filepath')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# setup classs names\n",
    "class_names = sorted([i for i in os.listdir('data/lion_tiger_wolf/train')])\n",
    "\n",
    "# Setup device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# get image path\n",
    "IMG_PATH = args.image_path\n",
    "print(f'[INFO] Predicting on image: {IMG_PATH}')\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(filepath=args.model_path):\n",
    "  # Need to use hyperparameters for saved model\n",
    "  load_model = model_builder.TinyVGG(input_shape=3,\n",
    "                                     output_shape=len(class_names),\n",
    "                                     hidden_units=128).to(device)\n",
    "  print(f'[INFO] Loading in model from: {filepath}')\n",
    "  load_model.load_state_dict(torch.load(filepath))\n",
    "  return load_model\n",
    "\n",
    "def predict_on_image(image_path=IMG_PATH,\n",
    "                     filepath=args.model_path):\n",
    "  model=load_model(filepath)\n",
    "  image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
    "  image = image/255.\n",
    "  transform = torchvision.transforms.Resize(size=(64, 64))\n",
    "  image = transform(image)\n",
    "\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    image=image.to(device)\n",
    "    pred = model(image.unsqueeze(dim=0))\n",
    "    pred_probs = torch.softmax(pred, dim=1)\n",
    "    pred_label = torch.argmax(pred_probs, dim=1)\n",
    "    pred_label_class = class_names[pred_label]\n",
    "  print(f'[INFO] Pred class: {pred_label_class} and Pred Prob: {pred_probs.max():.3f}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  predict_on_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2277,
     "status": "ok",
     "timestamp": 1670004043114,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "lqCQES-RlQbT",
    "outputId": "41191c1f-da9a-4e20-bb07-c36befe40875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicting on image: /content/data/lion_tiger_wolf/val/lion/05d42c9bd8.jpg\n",
      "[INFO] Loading in model from: models/model.pth\n",
      "Traceback (most recent call last):\n",
      "  File \"predict.py\", line 61, in <module>\n",
      "    predict_on_image()\n",
      "  File \"predict.py\", line 45, in predict_on_image\n",
      "    model=load_model(filepath)\n",
      "  File \"predict.py\", line 40, in load_model\n",
      "    load_model.load_state_dict(torch.load(filepath))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'models/model.pth'\n"
     ]
    }
   ],
   "source": [
    "!python predict.py --image_path /content/data/lion_tiger_wolf/val/lion/05d42c9bd8.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AZd4BVWFkZC"
   },
   "source": [
    "# 7. Creating a Image predict and plot script - image_plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1670144772530,
     "user": {
      "displayName": "John Pinto",
      "userId": "13049805689452713408"
     },
     "user_tz": -330
    },
    "id": "tvO_0EG5NL5L",
    "outputId": "df993555-218e-4892-8a87-879fb56bc806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting image_plot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile image_plot.py\n",
    "\"\"\"\n",
    "Contins code to predict and plot an image\n",
    "\"\"\"\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# defining device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# creating a function for predicting and plotting\n",
    "def pred_and_plot_image(model: torch.nn.Module,\n",
    "                        image_path: str,\n",
    "                        class_names: List[str],\n",
    "                        image_size: Tuple[int, int],\n",
    "                        transform: torchvision.transforms = None,\n",
    "                        device: torch.device = device):\n",
    "  \"\"\"\n",
    "  Predict and plot an image\n",
    "  Args:\n",
    "    model: A model to perform prediction.\n",
    "    image_path: A path string of the image location.\n",
    "    class_names: A list of all the classes names.\n",
    "    image_size: A tuple with image size in shape of (height, width).\n",
    "    transform: Torchvision transforms compose class to transform the data,\n",
    "    device: A device either 'cuda' or 'cpu'.\n",
    "  \"\"\"\n",
    "  # open image\n",
    "  img = Image.open(image_path)\n",
    "  # create transformation\n",
    "  if transform is not None:\n",
    "    img_transform = transform\n",
    "  else:\n",
    "    img_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(image_size),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "  # predict image\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    img_transform = img_transform(img).unsqueeze(dim=0)\n",
    "    img_pred = model(img_transform.to(device))\n",
    "  img_pred_probs = torch.softmax(img_pred, dim=1)\n",
    "  img_pred_label = torch.argmax(img_pred_probs, dim=1)\n",
    "  # plot image\n",
    "  plt.figure()\n",
    "  plt.imshow(img)\n",
    "  plt.title(f'Pred: {class_names[img_pred_label]} | Prob: {img_pred_probs.max():.3f}')\n",
    "  plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oMsxEJlGytq"
   },
   "source": [
    "# Copying the python file to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weDJq2uW9CPT"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "for i in os.listdir('/content/'):\n",
    "  if i.endswith('.py'):\n",
    "    shutil.copy2(i, '/content/drive/MyDrive/Colab Notebooks/My Project/Image Classification/Animal Vision/model_scripts')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOMyiYtiXN38hteU4hFL1cJ",
   "mount_file_id": "10rpdkaMR3R_InqqonNsHmN2AZFAAqNuG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04a58a2e34d8448398af74722b3e77be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_395804aae56b4c11a9c62a1f3b58494d",
      "placeholder": "​",
      "style": "IPY_MODEL_c95a05d5d0df4bbd817488c90ae93a8d",
      "value": "100%"
     }
    },
    "10172dbca6a74238973eea0895a4f90a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c3354c57d904135adc17fe773b74c11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d91ba25acf04fab905663ac3cf7d22e",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10172dbca6a74238973eea0895a4f90a",
      "value": 5
     }
    },
    "395804aae56b4c11a9c62a1f3b58494d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d91ba25acf04fab905663ac3cf7d22e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fd3c05e65ed47f29179975dd2ff8d9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b8bea360dfc4d0fad18169f97d13455": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c95a05d5d0df4bbd817488c90ae93a8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2db99b9c4944e0fa63a14d96e9e43d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_04a58a2e34d8448398af74722b3e77be",
       "IPY_MODEL_1c3354c57d904135adc17fe773b74c11",
       "IPY_MODEL_f69dc78e13a449139d27a49281e95d0a"
      ],
      "layout": "IPY_MODEL_7fd3c05e65ed47f29179975dd2ff8d9f"
     }
    },
    "f69dc78e13a449139d27a49281e95d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6e1a5e2c5a5441e9586bae64ef7353d",
      "placeholder": "​",
      "style": "IPY_MODEL_9b8bea360dfc4d0fad18169f97d13455",
      "value": " 5/5 [02:37&lt;00:00, 31.77s/it]"
     }
    },
    "f6e1a5e2c5a5441e9586bae64ef7353d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
